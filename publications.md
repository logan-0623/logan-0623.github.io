---
layout: page
title: Publications
permalink: /publications/
---

<!-- # Publications -->

## 2025

###  Conference Papers

#### **BIBM 2025** (IEEE International Conference on Bioinformatics and Biomedicine)
**PG-SAM: Prior-Guided SAM with Medical for Multi-organ Segmentation**
- *Yiheng Zhong\*, **Zihong Luo**\*, Chengzhi Liu, Feilong Tang, Zelin Peng, Ming Hu, Yingzhen Hu, Jionglong Su, Zongyuan Ge, Imran Razzak*
- **Research Focus:** Multi-modal fusion 路 Vision-Language alignment 路 Robust segmentation
-  [ArXiv](https://arxiv.org/abs/2503.18227) |  Status: **Accepted**

> Developed a **vision-language fusion framework** leveraging LLMs to align textual priors with visual features. Demonstrates expertise in **multi-modal representation learning** and **robust AI systems** applicable to robotics perception.

#### **AAAI 2025** (Top-tier AI Conference, CCF-A)
**Incomplete Modality Disentangled Representation for Ophthalmic Disease Grading and Diagnosis**
- *Chengzhi Liu\*, Zile Huang\*, Feilong Tang, Yu Tian, Zhongxing Xu, **Zihong Luo**, Yalin Zheng, Yanda Meng*
- **Research Focus:** Representation learning 路 Incomplete data handling 路 Feature disentanglement
-  [OpenReview](https://openreview.net/forum?id=IlJw8PAYYS) |  Status: **Accepted**

> Proposed **disentangled representation learning** to handle incomplete modalities and noisy sensor data. This methodology is directly applicable to **robotic sensor fusion** where sensors may fail or provide partial observations.

---

## 2024

###  Conference Papers

#### **ICANN 2024** (International Conference on Artificial Neural Networks)
**ARIF: An Adaptive Attention-Based Cross-Modal Representation Integration Framework**
- *Chengzhi Liu\*, **Zihong Luo**\*, Yifei Bi\*, Zile Huang, Dong Shu, Jiheng Hou, Hongchen Wang, Kaiyu Liang*
- **Research Focus:** Cross-modal learning 路 Attention mechanisms 路 Multi-modal fusion
-  [Springer](https://link.springer.com/chapter/10.1007/978-3-031-72347-6_1) |  Status: **Published**

> Built **adaptive attention mechanisms** for integrating multi-modal representations. Relevant to **vision-language-action models** in robotics where multiple sensory modalities need to be fused intelligently.

#### **ICPR 2024** (International Conference on Pattern Recognition)
**MTSA-SNN: A Multi-modal Time Series Analysis Model Based on Spiking Neural Network**
- *Chengzhi Liu\*, **Zihong Luo**\*, Zheng Tao, Yitao Xu, Zile Huang*
- **Research Focus:** Spiking neural networks 路 Temporal modeling 路 Energy-efficient AI
-  [ArXiv](https://arxiv.org/abs/2402.05423) |  Status: **Published**

> Developed **energy-efficient neural architectures** using spiking networks for multi-modal time-series data. SNNs are promising for **low-power robotic systems** and neuromorphic computing.

#### **ICPR 2024** (International Conference on Pattern Recognition)
**MC-DBN: A Deep Belief Network-Based Model for Modality Completion**
- ***Zihong Luo**\*, Chengzhi Liu\*, Zheng Tao, Heke Xin, Yitao Xu*
- **Research Focus:** Missing data imputation 路 Probabilistic models 路 Robust AI
-  [ArXiv](https://www.arxiv.org/abs/2402.09782) |  Status: **Published**

> Designed **robust algorithms for handling missing modalities** in multi-modal systems. Critical for **real-world robotics** where sensor failures are common.

###  Journal Articles

**Interpretable machine learning models for detecting peripheral neuropathy and lower extremity arterial disease in diabetics**
- *Ya Wu, Danmeng Dong, Lijie Zhu, **Zihong Luo**, Yang Liu, Xiaoyun Xie*
- BMC Medical Informatics and Decision Making (2024)
-  [Journal Article](https://link.springer.com/article/10.1186/s12911-024-02595-z) |  Status: **Published**

---

**\* Equal contribution**

---

## Research Statistics
- **Total Publications:** 6 papers
- **First/Co-first Author:** 4 papers
- **Top-tier Conferences:** BIBM, AAAI (CCF-A), ICANN, ICPR
- **Research Expertise:** Multi-modal Learning 路 Representation Learning 路 Robust AI Systems

---

##  Connect with My Research
-  [Google Scholar](#) - Full publication list
-  [GitHub](https://github.com/logan-0623) - Code repositories
-  [Email](mailto:Z.Luo21@student.liverpool.ac.uk) - Collaboration inquiries 